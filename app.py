#ownerclan_weekly_0428_ì „ì¹˜ë¦¬ LLM(ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¸¡) ì¶”ê°€ìš©
import numpy as np
from langchain_openai import OpenAI, OpenAIEmbeddings
from pymilvus import Collection, connections
import os
from openai import OpenAI as OpenAIClient      # ê³µì‹ OpenAI í´ë¼ì´ì–¸íŠ¸
import json
import re
import base64
import urllib
from langdetect import detect
from collections import defaultdict, Counter
import math

from typing import List, Dict, Any, Tuple
import time
import pandas as pd
from flask import Flask, render_template, request, session, redirect, url_for
import secrets
from user_events import event_manager
from datetime import datetime
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY    = os.getenv('OPENAI_API_KEY', 'your_openai_api_key_here')                    # â† í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
COLLECTION = "ownerclan_weekly_0428"            # Milvus ì»¬ë ‰ì…˜ ì´ë¦„
EMB_MODEL  = "text-embedding-3-small"
MILVUS_HOST = os.getenv('MILVUS_HOST', '114.110.135.96')
MILVUS_PORT = os.getenv('MILVUS_PORT', '19530')
LLM_MODEL  = "gpt-4.1-mini"

# í´ë¼ì´ì–¸íŠ¸ ë° ë˜í¼
client    = OpenAIClient(api_key=API_KEY)
llm       = OpenAI(api_key=API_KEY, model=LLM_MODEL, temperature=0)
embedder  = OpenAIEmbeddings(api_key=API_KEY, model=EMB_MODEL)    # â† embedder ì •ì˜ ì¶”ê°€
API_URL = "https://fb-narosu.duckdns.org"  # ì˜ˆ: http://114.110.135.96:8011

#ê°€ê²© ì¡°ê±´ íŒŒì‹±
pattern = re.compile(r'(\d+)[^\d]*ì›\s*(ì´í•˜|ë¯¸ë§Œ|ì´ìƒ|ì´ˆê³¼)')


# 1) Milvus ì„œë²„ì— ë¨¼ì € ì—°ê²°
connections.connect(
    alias="default",
    host=MILVUS_HOST,    # ì˜ˆ: "114.110.135.96"
    port=MILVUS_PORT     # ì˜ˆ: "19530"
)
print("âœ… Milvusì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")

app = Flask(__name__)
app.secret_key = secrets.token_hex(16)  # ì„¸ì…˜ì„ ìœ„í•œ ì‹œí¬ë¦¿ í‚¤




def run_recommendation_pipeline(query, price_min, price_max):
    collection_cat = Collection("category_0710")
    results = collection_cat.query(
        expr="category_full != ''",
        output_fields=["category_full"]
    )

    # â”€â”€ ì¤‘ë³µ ì œê±°í•˜ë©° ìˆœì„œ ë³´ì¡´í•´ì„œ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€
    seen = set()
    categories = []
    for row in results:
        cat = row["category_full"]
        if cat and cat not in seen:
            seen.add(cat)
            categories.append(cat)

    print(f"âœ… Milvusì—ì„œ ë¶ˆëŸ¬ì˜¨ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜: {len(categories)}")



    collection = Collection(COLLECTION)   #ë‹¤ì‹œ ìƒí’ˆ DB ì»¬ë ‰ì…˜ìœ¼ë¡œ ì—°ê²°
    def convert_to_serializable(obj):
        if isinstance(obj, (np.int64, np.int32, np.float32, np.float64)):
            return obj.item()
        return obj

    PRODUCT_CACHE = {}

    def clean_html_content(html_raw: str) -> str:
        try:
            html_cleaned = html_raw.replace('\n', '').replace('\r', '')
            html_cleaned = html_cleaned.replace(""", "\"").replace(""", "\"").replace("'", "'").replace("'", "'")
            if html_cleaned.count("<center>") > html_cleaned.count("</center>"):
                html_cleaned += "</center>"
            if html_cleaned.count("<p") > html_cleaned.count("</p>"):
                html_cleaned += "</p>"
            return html_cleaned
        except Exception as e:
            print(f"âŒ HTML ì •ì œ ì˜¤ë¥˜: {e}")
            return html_raw

    def compute_top4_quota(
        candidates: List[Dict[str, Any]],
        max_total: int = 10,
        min_per_category: int = 1
    ) -> Dict[str, int]:
        """
        Top4 ì¹´í…Œê³ ë¦¬ ìë™ ì¶”ì¶œ & ë¹„ìœ¨ ê¸°ë°˜ quota ê³„ì‚°
        Returns: {ì¹´í…Œê³ ë¦¬: quota}
        """
        total = len(candidates)
        counts = Counter(item["ì¹´í…Œê³ ë¦¬"] for item in candidates)
        top4 = [cat for cat, _ in counts.most_common(4)]
        
        # ì´ˆê¸° quota ê³„ì‚° (floor + ìµœì†Œ ë³´ì¥)
        quotas = {
            cat: max(math.floor(counts[cat] / total * max_total), min_per_category)
            for cat in top4
        }
        
        # ë¶€ì¡±Â·ì´ˆê³¼ ë³´ì •
        diff = max_total - sum(quotas.values())
        if diff > 0:
            # ë¹„ì¤‘ í° ìˆœì„œëŒ€ë¡œ +1
            for cat, _ in counts.most_common():
                if cat in quotas and diff > 0:
                    quotas[cat] += 1
                    diff -= 1
        elif diff < 0:
            # ë¹„ì¤‘ ì‘ì€ ìˆœì„œëŒ€ë¡œ -1 (min ìœ ì§€)
            for cat, _ in reversed(counts.most_common()):
                if cat in quotas and quotas[cat] > min_per_category and diff < 0:
                    quotas[cat] -= 1
                    diff += 1
        
        return quotas

    def filter_top4_candidates(
        candidates: List[Dict[str, Any]]
    ) -> Tuple[List[Dict[str, Any]], List[str]]:
        """
        Top4 ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
        Returns: (filtered_candidates, top4_keys)
        """
        counts = Counter(item["ì¹´í…Œê³ ë¦¬"] for item in candidates)
        top4_keys = [cat for cat, _ in counts.most_common(4)]
        filtered = [item for item in candidates if item["ì¹´í…Œê³ ë¦¬"] in top4_keys]
        return filtered, top4_keys

    def prepare_recommendation(
        all_candidates: List[Dict[str, Any]],
        max_total: int = 20,
        min_per_category: int = 1
    ) -> Tuple[List[Dict[str, Any]], Dict[str, int], List[str]]:
        """
        1) Top4 í•„í„°ë§
        2) quota ê³„ì‚°
        Returns: (filtered_candidates, quotas, top4_keys)
        """
        filtered, top4_keys = filter_top4_candidates(all_candidates)
        quotas = compute_top4_quota(filtered, max_total, min_per_category)
        return filtered, quotas, top4_keys

    def quota_to_text(quota: Dict[str, int]) -> str:
        return "\n".join([f'- {cat}: {q}ê°œ' for cat, q in quota.items()])

    def compute_category_proportions(
        candidates: List[Dict[str, Any]]
    ) -> Dict[str, float]:
        total = len(candidates)
        if total == 0:
            return {}
        counts = Counter(item["ì¹´í…Œê³ ë¦¬"] for item in candidates)
        return {cat: cnt / total for cat, cnt in counts.items()}


        

    ##############################################################################ì›ë³¸ ì‚¬ìš©ì ì¿¼ë¦¬
 
    print("[Debug] Raw query:", query)            # â† ì—¬ê¸°ì—!
    lang_code = detect(query)

    print("[Debug] lang_code â†’", lang_code)   # â† ì´ ì¤„ ì¶”ê°€!
    #ê°€ê²©ì„ ì´í•´í•˜ëŠ” ë§¤í•‘
    m = pattern.search(query)
    if m:
        amount = int(m.group(1))
        comp  = m.group(2)
        # ë¶€ë“±í˜¸ ë§¤í•‘
        op_map = {"ì´í•˜":"<=", "ë¯¸ë§Œ":"<", "ì´ìƒ":">=", "ì´ˆê³¼":">"}
        price_op = op_map[comp]
        price_cond = f"market_price {price_op} {amount}"
    else:
        # ë””í´íŠ¸: ì œí•œ ì—†ìŒ
        price_cond = None

    # 2) ì–¸ì–´ ì½”ë“œ â†’ ì‚¬ëŒë§ ë§¤í•‘
    lang_map = {
        "ko": "í•œêµ­ì–´",
        "en": "English",
        "zh-cn": "ä¸­æ–‡",
        "ja": "æ—¥æœ¬èª",
        "vi": "Tiáº¿ng Viá»‡t",  # ë² íŠ¸ë‚¨ì–´
        "th": "à¹„à¸—à¸¢",        # íƒœêµ­ì–´
    }

    target_lang = lang_map.get(lang_code, "í•œêµ­ì–´")
    print("[Debug] Detected language â†’", target_lang)

    # LLM ì „ì²˜ë¦¬
    llm = OpenAI(
        api_key=API_KEY,
        model=LLM_MODEL,
        temperature=0
    )
    system_prompt = (
        f"""System:
    ë‹¹ì‹ ì€ (1) ê²€ìƒ‰ ì—”ì§„ì˜ ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” AIì´ì, (2) ì‡¼í•‘ëª° ê²€ìƒ‰ ë° ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì–´ë–¤ ì–¸ì–´ë¡œ ì…ë ¥ì´ ë˜ë“  ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë¬¸ì¥ ì˜ë¯¸ì— ë§ê²Œ ë²ˆì—­ ë¨¼ì € í•©ë‹ˆë‹¤.
    ì•„ë˜ëŠ” DBì—ì„œ ë¡œë“œëœ **ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ëª©ë¡**ì…ë‹ˆë‹¤.  
    ëª¨ë“  ì˜ˆì¸¡ì€ ì´ ëª©ë¡ ì•ˆì—ì„œë§Œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤:

    {categories}

    ë‹¤ìŒ ìˆœì„œëŒ€ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

    1) **ì „ì²˜ë¦¬ ë‹¨ê³„**  
    - ì‚¬ìš©ì ì›ë¬¸(query)ì—ì„œ ì˜¤íƒ€ êµì •, ë¶ˆìš©ì–´ ì œê±°, ì¤‘ë³µ í‘œí˜„ ì œê±° 
    - í•µì‹¬ í‚¤ì›Œë“œ í•˜ë‚˜ë¥¼ ë½‘ì•„ í‘œì¤€ì–´/ë™ì˜ì–´ë¡œ ì¹˜í™˜í•œ ë’¤  
    - **â€œê²€ìƒ‰ì‹(Search Query)â€**ìœ¼ë¡œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆë„ë¡ í¬ë§·íŒ…í•˜ì„¸ìš”.  

    2) **ì¹´í…Œê³ ë¦¬ ì˜ˆì¸¡ ë‹¨ê³„**  
    - ì „ì²˜ë¦¬ëœ ì¿¼ë¦¬(Preprocessed Query)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ê´€ì ìœ¼ë¡œ ìµœìƒìœ„ ì¹´í…Œê³ ë¦¬ í•˜ë‚˜ ì˜ˆì¸¡

    3) **ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬ ë‹¨ê³„**  
    - ì´ë¯¸ Milvus ë²¡í„° ê²€ìƒ‰ì„ í†µí•´ ì–»ì€ TOP N ê²°ê³¼ ë¦¬ìŠ¤íŠ¸(search_results)ë¥¼ ì…ë ¥ë°›ì•„  
    - ê° ê²°ê³¼ì˜ ë©”íƒ€ë°ì´í„°(id, ìƒí’ˆëª…, ì¹´í…Œê³ ë¦¬, ê°€ê²©, URL ë“±)ë¥¼ í™œìš©í•´  
    - 2ë²ˆì—ì„œ ì˜ˆì¸¡í•œ ì¹´í…Œê³ ë¦¬ì™€ ë§¤ì¹­ë˜ê±°ë‚˜ ì¸ì ‘í•œ ê²°ê³¼ë¥¼ ìš°ì„  ì •ë ¬í•˜ì„¸ìš”.

    4) **ì¶œë ¥ í˜•ì‹**ì€ ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤:

    Raw Query: "<query>"  
    Preprocessed Query: "<ì „ì²˜ë¦¬ëœ_ì¿¼ë¦¬>"
    Predicted Category: "<ì˜ˆì¸¡ëœ_ìµœìƒìœ„_ì¹´í…Œê³ ë¦¬>"

        """    
    )

    if price_cond:
        system_prompt += f"âš ï¸ ì‚¬ìš©ì ìš”ì²­ ì¡°ê±´: ê°€ê²©ì€ **{amount}ì› {comp}** ({price_cond})ì¸ ìƒí’ˆë§Œ ê³ ë ¤í•˜ì„¸ìš”.\n\n"



    resp = client.chat.completions.create(
        model=LLM_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": query}
        ],
        temperature=0
    )
    llm_response = resp.choices[0].message.content.strip()
    print("[Debug] LLM full response:\n", llm_response)  # â† ì—¬ê¸°ì—!


    #LLM ì‘ë‹µ íŒŒì‹±
    lines = [l.strip() for l in llm_response.splitlines() if l.strip()]
    preprocessed_query = next(
        l.split(":",1)[1].strip().strip('"')
        for l in lines if l.lower().startswith("preprocessed query")
    )
    predicted_category = next(
        l.split(":",1)[1].strip().strip('"')
        for l in lines if l.lower().startswith("predicted category")
    )
    # â† ì—¬ê¸°ì— í•œ ì¤„ ì¶”ê°€
    top_category = predicted_category.split(">")[0]

    print("[Debug] Preprocessed Query â†’", preprocessed_query)   # â† ì—¬ê¸°ì—!
    print("[Debug] top_category â†’", top_category)   # â† ì—¬ê¸°ì—!

    #ìµœí•˜ìœ„ ì¹´í…Œê³ ë¦¬
    lowest_subcategory = predicted_category.split(">")[-1]

    print("[Debug] lowest_subcategory â†’", lowest_subcategory)


    #ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    q_vec = embedder.embed_query(preprocessed_query)
    print(f"[Debug] q_vec length: {len(q_vec)}, sample: {q_vec[:5]}")  # â† ì—¬ê¸°ì—!

    # â‘  Stage1: ì§ì ‘ ë¬¸ìì—´ ê²€ìƒ‰ (boolean search)
    print("[Stage1] Direct name search ì‹œì‘")

    # â€œë‚¨ììš© í–¥ìˆ˜â€ â†’ ["ë‚¨ì", "í–¥ìˆ˜"] ë‘ í† í°ìœ¼ë¡œ AND ê²€ìƒ‰
    tokens = [t for t in re.sub(r"[ìš©\s]+", " ", preprocessed_query).split() if t]
    query_expr = " && ".join(f'market_product_name like "%{tok}%"'
        for tok in tokens
    )

    print("[Debug] Stage1 expr:", query_expr)
    direct_hits = collection.query(
        expr=query_expr,
        limit=200,
        output_fields=[
            "product_code",
            "category_code",
            "category_name",
            "market_product_name",
            "market_price",
            "shipping_fee",
            "shipping_type",
            "max_quantity",
            "composite_options",
            "image_url",
            "manufacturer",
            "model_name",
            "origin",
            "keywords",
            "description",
            "return_shipping_fee",
        ]
    )
    print("[Stage1] Direct hits count:", len(direct_hits))
    # ìƒ˜í”Œ ì¶œë ¥
    for i, row in enumerate(direct_hits[:7], 1):
        print(f"  [Stage1 ìƒ˜í”Œ {i}]: ì½”ë“œ={row['product_code']}, ì´ë¦„={row['market_product_name']}")


    print("\n[Stage2.5] ì§ì ‘ê²€ìƒ‰ results êµ¬ì„± ì‹œì‘")  
    raw_candidates = []
    for row in direct_hits:
        # e = hit.entity
        # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ë§í¬
        try:
            html_raw = row.get("description", "") or ""
            html_cleaned = clean_html_content(html_raw)
            if isinstance(html_raw, bytes):
                html_raw = html_raw.decode("cp949")
            encoded_html = base64.b64encode(
                html_cleaned.encode("utf-8", errors="ignore")
            ).decode("utf-8")
            safe_html = urllib.parse.quote_plus(encoded_html)
            preview_url = f"{API_URL}/preview?html={safe_html}"
        except Exception as err:
            print(f"âš ï¸ ë³¸ë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {err}")
            preview_url = "https://naver.com"

        # ìƒí’ˆë§í¬(fallback)
        product_link = row.get("product_link", "")
        if not product_link or product_link in ["ë§í¬ ì—†ìŒ", "#", None]:
            product_link = preview_url

        # ì˜µì…˜ íŒŒì‹±
        option_raw = str(row.get("composite_options", "")).strip()
        option_display = "ì—†ìŒ"
        if option_raw.lower() not in ["", "nan"]:
            parsed = []
            for line in option_raw.splitlines():
                try:
                    name, extra, _ = line.split(",")
                    extra = int(float(extra))
                    parsed.append(
                        f"{name.strip()}{f' (ï¼‹{extra:,}ì›)' if extra>0 else ''}"
                    )
                except Exception:
                    parsed.append(line.strip())
            option_display = "\n".join(parsed)

        # 10ê°œ í•œê¸€ ì†ì„±ìœ¼ë¡œ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        result_info = {
            "ìƒí’ˆì½”ë“œ":     str(row.get("product_code", "ì—†ìŒ")),
            "ì œëª©":        row.get("market_product_name", "ì œëª© ì—†ìŒ"),
            "ê°€ê²©":        convert_to_serializable(row.get("market_price", 0)),
            "ë°°ì†¡ë¹„":      convert_to_serializable(row.get("shipping_fee", 0)),
            "ì´ë¯¸ì§€":      row.get("image_url", "ì´ë¯¸ì§€ ì—†ìŒ"),
            "ì›ì‚°ì§€":      row.get("origin", "ì •ë³´ ì—†ìŒ"),
            "ìƒí’ˆë§í¬":    product_link,
            "ì˜µì…˜":        option_display,
            "ì¡°í•©í˜•ì˜µì…˜":  option_raw,
            "ìµœëŒ€êµ¬ë§¤ìˆ˜ëŸ‰": convert_to_serializable(row.get("max_quantity", 0)),
            "ì¹´í…Œê³ ë¦¬":    row.get("category_name", "ì¹´í…Œê³ ë¦¬ ì—†ìŒ"),
        }
        result_info_cleaned = {}
        for k, v in result_info.items():
            if isinstance(v, str):
                v = v.replace("\n", "").replace("\r", "").replace("\t", "")
            result_info_cleaned[k] = v
        raw_candidates.append(result_info_cleaned)

    # â‘¡ Stage2: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    # expr = f'category_name like "%{top_category}%"'   #ìµœìƒìœ„ ì¹´í…Œê³ ë¦¬
    expr = f'category_name like "%{lowest_subcategory}%"'   #ìµœí•˜ìœ„ ì¹´í…Œê³ ë¦¬
    milvus_results = collection.search(
        data=[q_vec],
        anns_field="emb",  # â† ë²¡í„° ì €ì¥ëœ í•„ë“œ ì´ë¦„
        param={"metric_type": "L2", "params": {"nprobe": 1536}},
        limit=200,
        expr=expr,                              # â† ì´ ì¤„ ì¶”ê°€
        output_fields = [
        "product_code",
        "category_code",
        "category_name",
        "market_product_name",
        "market_price",
        "shipping_fee",
        "shipping_type",
        "max_quantity",
        "composite_options",
        "image_url",
        "manufacturer",
        "model_name",
        "origin",
        "keywords",
        "description",
        "return_shipping_fee",
    ]
    )
    print(f"[Stage2] Vector hits count: {len(milvus_results[0])}")
    # ìƒ˜í”Œ ì¶œë ¥



    for i, hit in enumerate(milvus_results[0][:7], 1):
        e = hit.entity
        print(f"  [Stage2 ìƒ˜í”Œ {i}]: ì½”ë“œ={e.get('product_code')}, ì´ë¦„={e.get('market_product_name')}")

        
    #ë²¡í„° ê²€ìƒ‰ ë‹´ëŠ” ë¶€ë¶„
    for hits in milvus_results:
        for hit in hits:
            e = hit.entity
            # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ë§í¬
            try:
                html_raw = e.get("description", "") or ""
                html_cleaned = clean_html_content(html_raw)
                if isinstance(html_raw, bytes):
                    html_raw = html_raw.decode("cp949")
                encoded_html = base64.b64encode(
                    html_cleaned.encode("utf-8", errors="ignore")
                ).decode("utf-8")
                safe_html = urllib.parse.quote_plus(encoded_html)
                preview_url = f"{API_URL}/preview?html={safe_html}"
                # preview_url = f"{safe_html}"
            except Exception as err:
                print(f"âš ï¸ ë³¸ë¬¸ ì²˜ë¦¬ ì˜¤ë¥˜: {err}")
                preview_url = "https://naver.com"

            # ìƒí’ˆë§í¬(fallback)
            product_link = e.get("product_link", "")
            if not product_link or product_link in ["ë§í¬ ì—†ìŒ", "#", None]:
                product_link = preview_url

            # ì˜µì…˜ íŒŒì‹±
            option_raw = str(e.get("composite_options", "")).strip()
            option_display = "ì—†ìŒ"
            if option_raw.lower() not in ["", "nan"]:
                parsed = []
                for line in option_raw.splitlines():
                    try:
                        name, extra, _ = line.split(",")
                        extra = int(float(extra))
                        parsed.append(
                            f"{name.strip()}{f' (ï¼‹{extra:,}ì›)' if extra>0 else ''}"
                        )
                    except Exception:
                        parsed.append(line.strip())
                option_display = "\n".join(parsed)

            # 10ê°œ í•œê¸€ ì†ì„±ìœ¼ë¡œ ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
            result_info = {
                "ìƒí’ˆì½”ë“œ":     str(e.get("product_code", "ì—†ìŒ")),
                "ì œëª©":        e.get("market_product_name", "ì œëª© ì—†ìŒ"),
                "ê°€ê²©":        convert_to_serializable(e.get("market_price", 0)),
                "ë°°ì†¡ë¹„":      convert_to_serializable(e.get("shipping_fee", 0)),
                "ì´ë¯¸ì§€":      e.get("image_url", "ì´ë¯¸ì§€ ì—†ìŒ"),
                "ì›ì‚°ì§€":      e.get("origin", "ì •ë³´ ì—†ìŒ"),
                "ìƒí’ˆë§í¬":    product_link,
                "ì˜µì…˜":        option_display,
                "ì¡°í•©í˜•ì˜µì…˜":  option_raw,
                "ìµœëŒ€êµ¬ë§¤ìˆ˜ëŸ‰": convert_to_serializable(e.get("max_quantity", 0)),
                "ì¹´í…Œê³ ë¦¬":    e.get("category_name", "ì¹´í…Œê³ ë¦¬ ì—†ìŒ"),
            }

            # ë¬¸ìì—´ ì •ë¦¬ í›„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            result_info_cleaned = {}
            for k, v in result_info.items():
                if isinstance(v, str):
                    v = v.replace("\n", "").replace("\r", "").replace("\t", "")
                result_info_cleaned[k] = v
            raw_candidates.append(result_info_cleaned)

            # ìºì‹œì— ì•ˆì „ ì €ì¥
            product_code = result_info_cleaned.get("ìƒí’ˆì½”ë“œ")
            # if product_code and product_code != "ì—†ìŒ":
                # PRODUCT_CACHE[product_code] = result_info_cleaned

    # ê°œìˆ˜ ë° ìƒ˜í”Œ í™•ì¸
    print(f"[Stage2.5] raw_candidates count: {len(raw_candidates)}")
    for i, info in enumerate(raw_candidates[:3],1):
        print(f"  [raw_candidates ìƒ˜í”Œ {i}]:", info)


    # Stage2.5 ì™„ë£Œ í›„: ì›ë³¸ ë³´ê´€
    original_candidates = raw_candidates.copy()

    # â‘  Top4 í•„í„° + quota ê³„ì‚°
    filtered_cands, quotas, top4_keys = prepare_recommendation(
        all_candidates=original_candidates,
        max_total=10,
        min_per_category=1
    )

    print("ğŸ” Top4 ì¹´í…Œê³ ë¦¬:", top4_keys)
    print("ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ë³„ quota:", quotas)

    total = len(raw_candidates)
    print(f"ğŸ” ì´ í›„ë³´: {total}ê°œ")

    # ë¹„ìœ¨
    props = compute_category_proportions(filtered_cands)
    print("ğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¹„ìœ¨:")
    for cat, ratio in props.items():
        print(f"  {cat}: {ratio*100:.1f}%")

        

    # quota (ìµœì¢… 5ê°œ ë°°ì • ê¸°ì¤€ ì˜ˆì‹œ)
    quotas = compute_top4_quota(filtered_cands, max_total=10,min_per_category=1)
    print("ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ ê°œìˆ˜(quota):")
    for cat, q in quotas.items():
        print(f"  {cat}: {q}ê°œ")

    # â”€â”€ 3) Promptì— quota ê°€ì´ë“œ ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def quota_to_text(quota: Dict[str, int]) -> str:
        return "\n".join([f"- {cat}: {num}ê°œ" for cat, num in quota.items()])

    quota_text = quota_to_text(quotas)
    print(f"quota_text ->   {quota_text}")
    # í›„ë³´ ë¦¬ìŠ¤íŠ¸(ì›ë³¸ ì „ë¶€)

    candidate_list = "\n".join(
        f"{i+1}. {c['ì œëª©']} [{c['ì¹´í…Œê³ ë¦¬']}]"
        for i, c in enumerate(filtered_cands)
    )

    print("[Stage4] LLMì— ë„˜ê¸¸ í›„ë³´ ë¦¬ìŠ¤íŠ¸:\n", candidate_list[:300], "...")  # ì•ë¶€ë¶„ë§Œ ì¶œë ¥

    rank_prompt = f"""
    **ë‹µë³€ì€ ë°˜ë“œì‹œ "{target_lang}"ë¡œ í•´ì£¼ì„¸ìš”.**
    System: ë‹¹ì‹ ì€ ì‡¼í•‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœì¢… ë­í‚¹í•˜ëŠ” AIì…ë‹ˆë‹¤.
    User Query: "{query}"
    # ì˜ˆì¸¡ëœ ì¹´í…Œê³ ë¦¬: "{predicted_category}"
    # ì•„ë˜ í›„ë³´ë“¤ì€ ëª¨ë‘ ì´ ì¹´í…Œê³ ë¦¬ì— ì†í•©ë‹ˆë‹¤. 

    í›„ë³´ë¦¬ìŠ¤íŠ¸ : {candidate_list}ì—ëŠ” ì´ë¯¸ Top4 ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§ëœ ìƒí’ˆë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

    **ì§€ì¹¨:**
    1. **ì¹´í…Œê³ ë¦¬ë³„ í•„í„°ë§ ì ìš©**  
    - {quota_text}ì— ëª…ì‹œëœ ê° ì¹´í…Œê³ ë¦¬ë³„ í• ë‹¹ëŸ‰ë§Œí¼, candidate_listì—ì„œ ë°˜ë“œì‹œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ìƒí’ˆì„ ì •í™•íˆ ê·¸ ê°œìˆ˜ë§Œí¼ ë‚˜ì—´í•˜ì„¸ìš”.  
    - ì˜ˆ: â€œíŒ¨ì…˜ì˜ë¥˜>ë‚¨ì„±ì˜ë¥˜>í‹°ì…”ì¸ : 4ê°œâ€ë¼ë©´, í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ìƒí’ˆ 4ê°œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

    2. **ì¶”ê°€ íƒìƒ‰ ì§ˆë¬¸ ìƒì„± (ìµœëŒ€ 400ì)**  
    - ë‚˜ì—´ëœ ìƒí’ˆ ë©”íƒ€ë°ì´í„°(ìƒí’ˆì½”ë“œ, ì œëª©, ê°€ê²©, ì´ë¯¸ì§€ URL ë“±)ë¥¼ ì¢…í•©í•˜ì—¬, ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ìƒí’ˆì´ ì´ ëª©ë¡ì— ì—†ì„ ê²½ìš° ì„ íƒì„ ì¢í ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì„ **ìµœì†Œ 400ì **ë¡œ ì‘ì„±í•˜ì„¸ìš”.

    3. **ìµœì¢… ì„ íƒ**  
    - ì œì‹œëœ í›„ë³´ ì¤‘ ì‚¬ìš©ìì˜ ì˜ë„ì— ê°€ì¥ ì í•©í•œ í•­ëª©ì˜ ë²ˆí˜¸ë§Œì„ JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•˜ì„¸ìš”.  
    - ë°˜ë“œì‹œ **ì˜ˆì‹œì™€ ê°™ì€ í˜•ì‹**ìœ¼ë¡œë§Œ ì¶œë ¥í•©ë‹ˆë‹¤:  
        
    json
        [1,2,3,4,5]


    """
    resp2 = client.chat.completions.create(
        model=LLM_MODEL,
        messages=[{"role":"system","content":rank_prompt}],
        temperature=0
    )
    selection = resp2.choices[0].message.content.strip()
    print("[Stage4] Raw LLM selection:", selection)

    # 1) ë§ˆí¬ë‹¤ìš´ ì œê±°
    clean = re.sub(r'.*?\n', '', selection).replace('```', '').strip()
    print("[Stage4] Cleaned selection:", clean)

    match = re.search(r'\[(?:\s*\d+\s*,?)+\s*\]', clean)
    if match:
        arr_text = match.group(0)
        try:
            chosen_idxs = json.loads(arr_text)
        except json.JSONDecodeError:
            chosen_idxs = []
    else:
        chosen_idxs = []

    # â”€â”€ ì—¬ê¸°ì— ì¶”ê°€ â”€â”€
    # â‘¡.1 ì¸ë±ìŠ¤ ë²”ìœ„ ê²€ì¦
    max_n = len(filtered_cands)
    valid_idxs = [i for i in chosen_idxs if 1 <= i <= max_n]
    if len(valid_idxs) < len(chosen_idxs):
        print(f"âš ï¸ ì˜ëª»ëœ ì¸ë±ìŠ¤ ì œê±°ë¨: {set(chosen_idxs) - set(valid_idxs)}")
    if not valid_idxs:
        print("âš ï¸ ìœ íš¨ ì¸ë±ìŠ¤ ì—†ìŒ, ìƒìœ„ 10ê°œë¡œ Fallback")
        valid_idxs = list(range(1, min(11, max_n+1)))
    chosen_idxs = valid_idxs
    print("[Stage4] Final chosen indices:", chosen_idxs)
    # â”€â”€ ì—¬ê¸°ê¹Œì§€ ì¶”ê°€ â”€â”€

    # 3) ìµœì¢… ê²°ê³¼ ë§¤í•‘ â†’ raw_candidates ê¸°ì¤€
    final_results = [ filtered_cands[i-1] for i in chosen_idxs ]   #10ê°œ ì œí•œ ì‹œí‚¤ê¸°
    print("\nâœ… ìµœì¢… ì¶”ì²œ ìƒí’ˆ:")

    # â˜… ì—¬ê¸°ì— 10ê°œ ì´ìƒì´ë©´ ì• 10ê°œë§Œ ì‚¬ìš©í•˜ë„ë¡ ìë¥´ê¸° â˜…
    if len(final_results) > 10:
        final_results = final_results[:10]

    for idx, info in enumerate(final_results, start=1):
        PRODUCT_CACHE[info["ìƒí’ˆì½”ë“œ"]] = info
        
        print(f"\n[{idx}] {info['ì œëª©']}")
        print(f"   ì¹´í…Œê³ ë¦¬   : {info['ì¹´í…Œê³ ë¦¬']}")
        print(f"   ìƒí’ˆì½”ë“œ   : {info['ìƒí’ˆì½”ë“œ']}")
        print(f"   ê°€ê²©       : {info['ê°€ê²©']}ì›")
        print(f"   ë°°ì†¡ë¹„     : {info['ë°°ì†¡ë¹„']}ì›")
        print(f"   ì´ë¯¸ì§€     : {info['ì´ë¯¸ì§€']}")
        print(f"   ì›ì‚°ì§€     : {info['ì›ì‚°ì§€']}")
        print(f"   ìƒí’ˆë§í¬   : {info['ìƒí’ˆë§í¬']}")
        print(f"   ì˜µì…˜       : {info['ì˜µì…˜']}")
        print(f"   ì¡°í•©í˜•ì˜µì…˜ : {info['ì¡°í•©í˜•ì˜µì…˜']}")
        print(f"   ìµœëŒ€êµ¬ë§¤ìˆ˜ëŸ‰: {info['ìµœëŒ€êµ¬ë§¤ìˆ˜ëŸ‰']}")
    print(f"================================")
    print(f"PRODUCT_CACHE {PRODUCT_CACHE}")

    return final_results  # í…œí”Œë¦¿ì— ë„˜ê¸¸ ë¦¬ìŠ¤íŠ¸

@app.route('/track_view', methods=['POST'])
def track_product_view():
    """ìƒí’ˆ ìƒì„¸ë³´ê¸° í´ë¦­ ì´ë²¤íŠ¸ ì¶”ì """
    try:
        data = request.get_json()
        product_code = data.get('product_code')
        product_data = data.get('product_data', {})
        
        # ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        if 'session_id' not in session:
            session['session_id'] = secrets.token_hex(16)
        
        session_id = session['session_id']
        ip_address = request.remote_addr
        user_agent = request.headers.get('User-Agent', '')
        
        # ì‚¬ìš©ì ID ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        user_id = event_manager.get_or_create_user(session_id, ip_address, user_agent)
        
        # ìƒí’ˆ ì¡°íšŒ ì´ë²¤íŠ¸ ê¸°ë¡
        view_id = event_manager.record_product_view(
            user_id=user_id,
            session_id=session_id,
            product_data=product_data,
            ip_address=ip_address,
            user_agent=user_agent
        )
        
        return {'status': 'success', 'view_id': view_id, 'user_id': user_id}
    
    except Exception as e:
        return {'status': 'error', 'message': str(e)}, 500

@app.route('/user_stats')
def user_stats():
    """ì‚¬ìš©ì í†µê³„ ì •ë³´"""
    try:
        if 'session_id' not in session:
            return {'status': 'error', 'message': 'ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.'}
        
        session_id = session['session_id']
        user_id = event_manager.get_or_create_user(session_id)
        
        # ì‚¬ìš©ìë³„ í†µê³„
        user_views = event_manager.get_user_product_views(user_id, limit=10)
        user_searches = event_manager.get_user_search_history(user_id, limit=10)
        
        return {
            'status': 'success',
            'user_id': user_id,
            'recent_views': user_views,
            'recent_searches': user_searches
        }
    
    except Exception as e:
        return {'status': 'error', 'message': str(e)}, 500

@app.route('/popular_products')
def popular_products():
    """ì¸ê¸° ìƒí’ˆ ì¡°íšŒ"""
    try:
        days = request.args.get('days', 7, type=int)
        limit = request.args.get('limit', 20, type=int)
        
        popular = event_manager.get_popular_products(days=days, limit=limit)
        return {'status': 'success', 'products': popular}
    
    except Exception as e:
        return {'status': 'error', 'message': str(e)}, 500

@app.route('/', methods=['GET', 'POST'])
def index():
    error = None
    results = None

    # ìƒˆë¡œê³ ì¹¨ ê°ì§€ (Cache-Control í—¤ë” í™•ì¸)
    cache_control = request.headers.get('Cache-Control', '')
    is_refresh = 'no-cache' in cache_control or request.headers.get('Pragma') == 'no-cache'

    if request.method == 'POST':
        query     = request.form.get('query', '').strip()
        price_min = request.form.get('price_min', type=int)
        price_max = request.form.get('price_max', type=int)

        if not query:
            error = 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.'
            return render_template('index.html', error=error, results=None)
        else:
            try:
                # ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
                if 'session_id' not in session:
                    session['session_id'] = secrets.token_hex(16)
                
                session_id = session['session_id']
                ip_address = request.remote_addr
                user_agent = request.headers.get('User-Agent', '')
                
                # ì‚¬ìš©ì ID ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
                user_id = event_manager.get_or_create_user(session_id, ip_address, user_agent)
                
                # ê²€ìƒ‰ ê²°ê³¼ ìƒì„±
                results = run_recommendation_pipeline(query, price_min, price_max)
                
                # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ê¸°ë¡
                results_count = len(results) if results else 0
                event_manager.record_search_event(
                    user_id=user_id,
                    session_id=session_id,
                    query=query,
                    price_min=price_min,
                    price_max=price_max,
                    results_count=results_count,
                    ip_address=ip_address,
                    user_agent=user_agent
                )
                
                # ê²°ê³¼ì™€ í•¨ê»˜ í˜ì´ì§€ ë Œë”ë§
                return render_template('index.html', error=error, results=results)
                
            except Exception as ex:
                error = f"ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {ex}"
                return render_template('index.html', error=error, results=None)

    # GET ìš”ì²­ ì²˜ë¦¬ - ìƒˆë¡œê³ ì¹¨ì´ê±°ë‚˜ ì¼ë°˜ GET ìš”ì²­ì¸ ê²½ìš° ê²°ê³¼ ì´ˆê¸°í™”
    # ì„¸ì…˜ì—ì„œ ê²€ìƒ‰ ê´€ë ¨ ë°ì´í„° ì •ë¦¬
    session.pop('search_results', None)
    session.pop('search_query', None)
    session.pop('search_price_min', None)
    session.pop('search_price_max', None)
    
    return render_template('index.html', error=error, results=results)

if __name__ == '__main__':
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    host = '0.0.0.0'
    port = '7070'
    debug = False     # production ëª¨ë“œì´ë¯€ë¡œ ë””ë²„ê·¸ ë”
    
    print(f"ğŸš€ ì„œë²„ ì‹œì‘: {host}:{port} (debug={debug})")
    app.run(host=host, port=port, debug=debug)







